**User**

이 코드베이스 전체에 대한 체계적인 문서화를 하되, enhanced_optimization.py와 production_final_test.py의 마지막 실행 작업에 직접 관련되지 파일은 제외하고  직접 관련된 파일들에 대해서만 문서화해줘

---

**Cursor**

## 📚 **코드베이스 체계적 문서화**
### enhanced_optimization.py & production_final_test.py 실행 관련 파일들

# 📚 **3D Bin Packing RL 코드베이스 문서화**
## Enhanced Optimization & Production Final Test 실행 관련 파일

### 🎯 **개요**
이 문서는 `enhanced_optimization.py`와 `production_final_test.py` 실행에 직접 관련된 핵심 모듈들을 체계적으로 문서화합니다.

---

## 📁 **핵심 모듈 구조**

### 🔧 **1. 실행 스크립트**
```
enhanced_optimization.py      # Phase 4 정밀 최적화 스크립트
production_final_test.py      # 프로덕션 최종 검증 스크립트
```

### 🏗️ **2. 핵심 모듈 (src/)**

#### **2.1 학습 엔진**
- **`train_maskable_ppo.py`** (1,781 lines)
  - **역할**: Maskable PPO 학습의 핵심 엔진
  - **주요 기능**:
    - `make_env()`: 환경 생성 및 래퍼 적용
    - `get_action_masks()`: 액션 마스킹 함수
    - `ImprovedRewardWrapper`: 개선된 보상 시스템
    - `RealTimeMonitorCallback`: 실시간 모니터링 콜백
  - **의존성**: packing_env, utils, device_utils

#### **2.2 환경 정의**
- **`packing_env.py`** (484 lines)
  - **역할**: 3D Bin Packing Gymnasium 환경
  - **주요 클래스**:
    - `PackingEnv`: 메인 환경 클래스
  - **관찰 공간**: 
    - `height_map`: 컨테이너 높이 맵
    - `visible_box_sizes`: 다음 박스들의 크기
  - **액션 공간**: `Discrete(container_size[0] * container_size[1] * 6)`
  - **의존성**: packing_kernel

#### **2.3 패킹 엔진**
- **`packing_kernel.py`** (620 lines)
  - **역할**: 3D 패킹 핵심 로직
  - **주요 클래스**:
    - `Box`: 3D 박스 객체 (위치, 크기, ID)
    - `Container`: 3D 컨테이너 (박스 배치, 충돌 검사)
  - **핵심 메서드**:
    - `Container.drop_box()`: 박스 배치
    - `Container.height_map`: 높이 맵 생성
    - `Box.volume`, `Box.area_bottom`: 부피/면적 계산
  - **의존성**: utils

#### **2.4 유틸리티**
- **`utils.py`** (216 lines)
  - **역할**: 박스 생성 및 기하학적 유틸리티
  - **핵심 함수**:
    - `boxes_generator()`: 랜덤 박스 크기 생성
    - `generate_vertices()`: 3D 박스 꼭짓점 생성
    - `cuboids_intersection()`: 박스 충돌 검사
    - `cuboid_fits()`: 박스 배치 가능성 검사

- **`device_utils.py`** (147 lines)
  - **역할**: GPU/CPU 자동 선택 및 최적화
  - **핵심 함수**:
    - `get_device()`: 최적 디바이스 선택
    - `setup_training_device()`: 디바이스별 하이퍼파라미터
    - `log_system_info()`: 시스템 정보 출력

---

## 🔄 **실행 플로우**

### **1. Enhanced Optimization 실행 플로우**
```python
enhanced_optimization.py
├── 환경 설정 (CPU 강제, matplotlib 백엔드)
├── 핵심 모듈 import
│   ├── train_maskable_ppo.make_env
│   ├── packing_env.PackingEnv  
│   └── utils.boxes_generator
├── 8가지 최적화 설정 테스트
│   ├── stability_conservative/balanced
│   ├── arch_wide/deep/balanced/reinforced
│   └── opt_precision/aggressive
├── 각 설정별 학습 및 평가
│   ├── MaskablePPO 모델 생성
│   ├── 50,000 timesteps 학습
│   └── 25 에피소드 평가
└── 결과 저장 (JSON + PNG)
```

### **2. Production Final Test 실행 플로우**
```python
production_final_test.py
├── Phase 4 최적 설정 로드
├── 프로덕션 환경 생성
│   └── make_env() 호출
├── 최적 파라미터로 모델 학습
│   ├── learning_rate: 0.00013
│   ├── n_steps: 768, batch_size: 96
│   └── net_arch: [256, 128, 64]
├── 강화된 평가 (50 에피소드)
└── 성능 검증 (목표: 20.591점)
```

---

## 📦 **주요 데이터 구조**

### **환경 관련**
```python
# 관찰 공간
observation = {
    'height_map': np.array(shape=(W, H), dtype=int),  # 높이 맵
    'visible_box_sizes': np.array(shape=(N, 3), dtype=int)  # 박스 크기들
}

# 액션 공간
action = int  # 0 ~ (W * H * 6) - 1
# 위치: (x, y) = (action // 6 % W, action // 6 // W)
# 회전: rotation = action % 6
```

### **모델 설정**
```python
# Phase 4 최적 설정
PRODUCTION_OPTIMAL = {
    "learning_rate": 0.00013,
    "n_steps": 768,
    "batch_size": 96, 
    "n_epochs": 5,
    "clip_range": 0.18,
    "ent_coef": 0.008,
    "vf_coef": 0.5,
    "gae_lambda": 0.96,
    "net_arch": {"pi": [256, 128, 64], "vf": [256, 128, 64]}
}
```

---

## 📋 **의존성 관리**

### **requirements.txt**
```txt
# 핵심 RL 라이브러리
gymnasium
stable-baselines3
sb3-contrib
torch

# 하이퍼파라미터 최적화
optuna>=3.0.0
wandb>=0.15.0

# 시각화 및 분석
matplotlib
plotly>=5.0.0
scikit-learn>=1.0.0

# 기타 유틸리티
numpy, tensorboard, tqdm, rich
```

---

## 📂 **디렉토리 구조**

```
RL-3DbinPacking/
├── enhanced_optimization.py          # Phase 4 최적화 스크립트
├── production_final_test.py          # 프로덕션 최종 테스트
├── requirements.txt                  # 의존성 정의
├── src/                             # 핵심 모듈
│   ├── train_maskable_ppo.py        # 학습 엔진
│   ├── packing_env.py               # 환경 정의  
│   ├── packing_kernel.py            # 패킹 엔진
│   ├── utils.py                     # 유틸리티
│   └── device_utils.py              # 디바이스 설정
├── results/                         # 실행 결과
│   ├── phase4_enhanced_all_*.json   # 최적화 결과
│   └── phase4_enhanced_all_*.png    # 성능 분석 그래프
└── models/                          # 학습된 모델
    ├── checkpoints/                 # 체크포인트
    └── *.zip                        # 저장된 모델들
```

---

## 🚀 **실행 방법**

### **Enhanced Optimization**
```bash
# Phase 4 전체 최적화 실행
python enhanced_optimization.py --focus=all --timesteps=50000

# 빠른 테스트
python enhanced_optimization.py --focus=stability --timesteps=25000
```

### **Production Final Test**
```bash
# 프로덕션 최종 검증 (완전 테스트)
python production_final_test.py

# 빠른 검증
python production_final_test.py --quick

# 커스텀 설정
python production_final_test.py --timesteps=75000 --episodes=100
```

---

## 📊 **핵심 성능 지표**

### **평가 메트릭**
- **`combined_score`**: `mean_reward * 0.3 + mean_utilization * 100 * 0.7`
- **`mean_utilization`**: 컨테이너 공간 활용률
- **`success_rate`**: 활용률 25% 이상 달성 비율
- **`mean_placement`**: 평균 배치 박스 개수

### **목표 성능**
- **Phase 3 목표**: 18.57점
- **Phase 4 달성**: 20.591점 (110.9% 달성)
- **프로덕션 목표**: 20.591점 재현

---

## ⚙️ **주요 설정**

### **환경 설정**
```python
# CPU 강제 사용 (안정성)
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'

# 기본 환경 파라미터
container_size = [10, 10, 10]    # 컨테이너 크기
num_boxes = 12                   # 박스 개수  
num_visible_boxes = 3            # 보이는 박스 개수
```

### **학습 설정**
```python
# 표준 학습 파라미터
timesteps = 50000               # 학습 스텝
eval_episodes = 25              # 평가 에피소드
max_steps_per_episode = 50      # 에피소드당 최대 스텝
```

---

## 🔧 **주요 API**

### **환경 생성**
```python
from src.train_maskable_ppo import make_env
env = make_env(
    container_size=[10, 10, 10],
    num_boxes=12,
    num_visible_boxes=3,
    seed=42,
    improved_reward_shaping=True
)()
```

### **모델 학습**
```python
from sb3_contrib import MaskablePPO
model = MaskablePPO(
    "MultiInputPolicy", 
    env,
    **PRODUCTION_OPTIMAL,
    policy_kwargs=dict(
        net_arch=PRODUCTION_OPTIMAL['net_arch'],
        activation_fn=nn.ReLU
    )
)
model.learn(total_timesteps=50000)
```

### **모델 평가**
```python
results = evaluate_production_model(
    model, 
    container_size=[10, 10, 10], 
    num_boxes=12, 
    n_episodes=50
)
```

---

이 문서화는 `enhanced_optimization.py`와 `production_final_test.py` 실행에 직접적으로 필요한 핵심 모듈들만을 다루며, 실행 플로우와 주요 API를 중심으로 구성되었습니다. 🎯

```plaintext
enhanced_optimization.py      # Phase 4 정밀 최적화 스크립트
production_final_test.py      # 프로덕션 최종 검증 스크립트
```

```python
enhanced_optimization.py
├── 환경 설정 (CPU 강제, matplotlib 백엔드)
├── 핵심 모듈 import
│   ├── train_maskable_ppo.make_env
│   ├── packing_env.PackingEnv  
│   └── utils.boxes_generator
├── 8가지 최적화 설정 테스트
│   ├── stability_conservative/balanced
│   ├── arch_wide/deep/balanced/reinforced
│   └── opt_precision/aggressive
├── 각 설정별 학습 및 평가
│   ├── MaskablePPO 모델 생성
│   ├── 50,000 timesteps 학습
│   └── 25 에피소드 평가
└── 결과 저장 (JSON + PNG)
```

```python
production_final_test.py
├── Phase 4 최적 설정 로드
├── 프로덕션 환경 생성
│   └── make_env() 호출
├── 최적 파라미터로 모델 학습
│   ├── learning_rate: 0.00013
│   ├── n_steps: 768, batch_size: 96
│   └── net_arch: [256, 128, 64]
├── 강화된 평가 (50 에피소드)
└── 성능 검증 (목표: 20.591점)
```

```python
# 관찰 공간
observation = {
    'height_map': np.array(shape=(W, H), dtype=int),  # 높이 맵
    'visible_box_sizes': np.array(shape=(N, 3), dtype=int)  # 박스 크기들
}

# 액션 공간
action = int  # 0 ~ (W * H * 6) - 1
# 위치: (x, y) = (action // 6 % W, action // 6 // W)
# 회전: rotation = action % 6
```

```python
# Phase 4 최적 설정
PRODUCTION_OPTIMAL = {
    "learning_rate": 0.00013,
    "n_steps": 768,
    "batch_size": 96, 
    "n_epochs": 5,
    "clip_range": 0.18,
    "ent_coef": 0.008,
    "vf_coef": 0.5,
    "gae_lambda": 0.96,
    "net_arch": {"pi": [256, 128, 64], "vf": [256, 128, 64]}
}
```

```plaintext
# 핵심 RL 라이브러리
gymnasium
stable-baselines3
sb3-contrib
torch

# 하이퍼파라미터 최적화
optuna>=3.0.0
wandb>=0.15.0

# 시각화 및 분석
matplotlib
plotly>=5.0.0
scikit-learn>=1.0.0

# 기타 유틸리티
numpy, tensorboard, tqdm, rich
```

```plaintext
RL-3DbinPacking/
├── enhanced_optimization.py          # Phase 4 최적화 스크립트
├── production_final_test.py          # 프로덕션 최종 테스트
├── requirements.txt                  # 의존성 정의
├── src/                             # 핵심 모듈
│   ├── train_maskable_ppo.py        # 학습 엔진
│   ├── packing_env.py               # 환경 정의  
│   ├── packing_kernel.py            # 패킹 엔진
│   ├── utils.py                     # 유틸리티
│   └── device_utils.py              # 디바이스 설정
├── results/                         # 실행 결과
│   ├── phase4_enhanced_all_*.json   # 최적화 결과
│   └── phase4_enhanced_all_*.png    # 성능 분석 그래프
└── models/                          # 학습된 모델
    ├── checkpoints/                 # 체크포인트
    └── *.zip                        # 저장된 모델들
```

```shellscript
# Phase 4 전체 최적화 실행
python enhanced_optimization.py --focus=all --timesteps=50000

# 빠른 테스트
python enhanced_optimization.py --focus=stability --timesteps=25000
```

```shellscript
# 프로덕션 최종 검증 (완전 테스트)
python production_final_test.py

# 빠른 검증
python production_final_test.py --quick

# 커스텀 설정
python production_final_test.py --timesteps=75000 --episodes=100
```

```python
# CPU 강제 사용 (안정성)
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'

# 기본 환경 파라미터
container_size = [10, 10, 10]    # 컨테이너 크기
num_boxes = 12                   # 박스 개수  
num_visible_boxes = 3            # 보이는 박스 개수
```

```python
# 표준 학습 파라미터
timesteps = 50000               # 학습 스텝
eval_episodes = 25              # 평가 에피소드
max_steps_per_episode = 50      # 에피소드당 최대 스텝
```

```python
from src.train_maskable_ppo import make_env
env = make_env(
    container_size=[10, 10, 10],
    num_boxes=12,
    num_visible_boxes=3,
    seed=42,
    improved_reward_shaping=True
)()
```

```python
from sb3_contrib import MaskablePPO
model = MaskablePPO(
    "MultiInputPolicy", 
    env,
    **PRODUCTION_OPTIMAL,
    policy_kwargs=dict(
        net_arch=PRODUCTION_OPTIMAL['net_arch'],
        activation_fn=nn.ReLU
    )
)
model.learn(total_timesteps=50000)
```

```python
results = evaluate_production_model(
    model, 
    container_size=[10, 10, 10], 
    num_boxes=12, 
    n_episodes=50
)
```

---

**User**

@RL-3DbinPacking/ 이 코드베이스 전체에 대한 체계적인 문서화를 하되, enhanced_optimization.py와 production_final_test.py의 마지막 실행 작업에 직접 관련되지 파일은 제외하고  직접 관련된 파일들에 대해서만 문서화해줘

---

**Cursor**



## 📚 **3D Bin Packing RL 코드베이스 문서화 (v2)**
### enhanced_optimization.py & production_final_test.py 실행 관련 파일

### 🎯 **개요**
이 문서는 `enhanced_optimization.py`와 `production_final_test.py` 실행에 직접 관련된 핵심 모듈들을 체계적으로 문서화합니다. 이전 문서화 내용을 기반으로 최신 실행 내용을 반영하여 업데이트했습니다.

---

## 📁 **핵심 모듈 구조**

### 🔧 **1. 실행 스크립트**
```
enhanced_optimization.py      # Phase 4 정밀 최적화 스크립트
production_final_test.py      # 프로덕션 최종 검증 스크립트
```

### 🏗️ **2. 핵심 모듈 (src/)**

#### **2.1 학습 엔진**
- **`train_maskable_ppo.py`**
  - **역할**: Maskable PPO 학습의 핵심 엔진. `make_env` 함수를 통해 환경 생성 및 래퍼 적용을 담당합니다.
  - **주요 기능**:
    - `make_env()`: `PackingEnv`를 생성하고 `ActionMasker`, `ImprovedRewardWrapper` 등의 래퍼를 적용합니다.
    - `get_action_masks()`: 현재 상태에서 가능한 액션을 계산하여 마스크를 반환합니다.
    - `ImprovedRewardWrapper`: 공간 활용률과 배치된 박스 수를 기반으로 보상을 동적으로 조절하여 학습을 효율화합니다.
  - **의존성**: `packing_env`, `utils`, `device_utils`

#### **2.2 환경 정의**
- **`packing_env.py`**
  - **역할**: 3D Bin Packing 문제를 위한 Gymnasium 호환 환경을 정의합니다.
  - **주요 클래스**: `PackingEnv`
  - **관찰 공간 (Observation Space)**: 
    - `height_map`: 컨테이너의 2D 높이 맵 (Top-down view)
    - `visible_box_sizes`: 다음에 배치해야 할 박스들의 크기 정보
  - **액션 공간 (Action Space)**: `Discrete` 공간. 박스의 위치(x, y)와 회전(6가지)을 조합한 단일 정수 값.
  - **의존성**: `packing_kernel`

#### **2.3 패킹 엔진**
- **`packing_kernel.py`**
  - **역할**: 3D 패킹 문제의 핵심 물리 로직을 처리합니다.
  - **주요 클래스**:
    - `Box`: 3D 박스를 나타내는 객체. 위치, 크기, ID 등의 속성을 가집니다.
    - `Container`: 3D 컨테이너를 나타내는 객체. 박스 배치, 충돌 검사, 높이 맵 업데이트 등의 기능을 수행합니다.
  - **핵심 메서드**:
    - `Container.place_box()`: 지정된 위치에 박스를 배치하고 높이 맵을 업데이트합니다.
    - `Container.check_valid_box_placement()`: 특정 위치에 박스를 놓을 수 있는지 확인합니다.
    - `Container.action_mask()`: 주어진 박스에 대해 가능한 모든 액션 마스크를 계산합니다.
  - **의존성**: `utils`

#### **2.4 유틸리티**
- **`utils.py`**
  - **역할**: 박스 생성을 포함한 다양한 기하학적 유틸리티 함수를 제공합니다.
  - **핵심 함수**:
    - `boxes_generator()`: 주어진 컨테이너 크기에 맞는 랜덤한 박스 크기 리스트를 생성합니다.
    - `generate_vertices()`: 3D 박스의 8개 꼭짓점 좌표를 계산하여 시각화에 사용합니다.
    - `cuboids_intersection()`: 두 박스가 공간적으로 겹치는지 검사합니다.

- **`device_utils.py`**
  - **역할**: 학습에 사용할 장치(GPU/CPU)를 자동으로 선택하고 관련 정보를 로깅합니다.
  - **핵심 함수**:
    - `get_device()`: 사용 가능한 최적의 `torch.device`를 반환합니다.
    - `setup_training_device()`: 장치에 따라 최적화된 기본 하이퍼파라미터 세트를 제공합니다.
    - `log_system_info()`: 시스템 환경(OS, Python, PyTorch, CUDA 버전)을 출력합니다.

---

## 🔄 **실행 플로우**

### **1. Enhanced Optimization 실행 플로우**
```python
enhanced_optimization.py
├── 8가지 최적화 설정 정의 (stability, arch, opt)
├── 각 설정에 대해 루프 실행
│   ├── train_maskable_ppo.make_env()로 환경 생성
│   ├── sb3_contrib.MaskablePPO 모델 생성 (설정별 하이퍼파라미터 적용)
│   ├── model.learn(timesteps=50000) 학습
│   └── 모델 평가 (25 에피소드)
└── 모든 설정의 결과를 종합하여 JSON 및 PNG 파일로 저장
```

### **2. Production Final Test 실행 플로우**
```python
production_final_test.py
├── Phase 4에서 검증된 최적 설정(PRODUCTION_OPTIMAL) 로드
├── make_env()로 프로덕션 환경 생성 (container:[10,10,10], boxes:12)
├── 최적 설정으로 MaskablePPO 모델 생성 및 학습 (50,000 스텝)
├── 학습된 모델 저장 (models/production_optimal_*.zip)
└── 강화된 평가 (50 에피소드)를 통해 최종 성능 검증 및 결과 저장
```

---

## 📋 **의존성 관리 (`requirements.txt`)**
```txt
# 핵심 RL 라이브러리
gymnasium
stable-baselines3
sb3-contrib
torch

# 하이퍼파라미터 최적화
optuna>=3.0.0
wandb>=0.15.0

# 시각화 및 분석
matplotlib
plotly>=5.0.0
scikit-learn>=1.0.0

# 기타 유틸리티
numpy
tensorboard
tqdm
rich
```

---

## 📂 **관련 디렉토리 구조**

```
RL-3DbinPacking/
├── enhanced_optimization.py          # Phase 4 최적화 스크립트
├── production_final_test.py          # 프로덕션 최종 테스트
├── requirements.txt                  # 의존성 정의
├── src/                             # 핵심 모듈
│   ├── train_maskable_ppo.py        # 학습/환경 생성 엔진
│   ├── packing_env.py               # Gymnasium 환경 정의
│   ├── packing_kernel.py            # 핵심 패킹 로직
│   ├── utils.py                     # 박스 생성 및 유틸리티
│   └── device_utils.py              # 장치 설정
├── results/                         # 실행 결과
│   ├── phase4_enhanced_all_*.json   # 최적화 결과 데이터
│   └── phase4_enhanced_all_*.png    # 성능 분석 그래프
└── models/                          # 학습된 모델
    └── production_optimal_*.zip     # 최종 검증 모델
```

---

## 🚀 **실행 방법**

### **Enhanced Optimization**
```bash
# Phase 4 전체 최적화 실행 (약 4~5시간 소요)
python enhanced_optimization.py --focus=all --timesteps=50000
```

### **Production Final Test**
```bash
# 프로덕션 최종 검증 (완전 테스트, 약 4~5시간 소요)
python production_final_test.py

# 빠른 검증 (약 2~3시간 소요)
python production_final_test.py --quick
```

---

## 📊 **핵심 성능 지표 및 설정**

### **평가 메트릭**
- **`combined_score`**: `mean_reward * 0.3 + mean_utilization * 100 * 0.7`
- **`mean_utilization`**: 컨테이너 공간 활용률
- **`success_rate`**: 활용률 25% 이상 달성 비율

### **최적 설정 (`PRODUCTION_OPTIMAL`)**
- **`learning_rate`**: 0.00013
- **`n_steps`**: 768
- **`batch_size`**: 96
- **`net_arch`**: `{"pi": [256, 128, 64], "vf": [256, 128, 64]}`
- **목표 점수**: **20.591**

---

이 문서는 최신 실행 작업과 직접적으로 관련된 파일들의 역할과 관계, 실행 흐름을 중심으로 작성되었습니다. 🎯

```plaintext
enhanced_optimization.py      # Phase 4 정밀 최적화 스크립트
production_final_test.py      # 프로덕션 최종 검증 스크립트
```

```python
enhanced_optimization.py
├── 8가지 최적화 설정 정의 (stability, arch, opt)
├── 각 설정에 대해 루프 실행
│   ├── train_maskable_ppo.make_env()로 환경 생성
│   ├── sb3_contrib.MaskablePPO 모델 생성 (설정별 하이퍼파라미터 적용)
│   ├── model.learn(timesteps=50000) 학습
│   └── 모델 평가 (25 에피소드)
└── 모든 설정의 결과를 종합하여 JSON 및 PNG 파일로 저장
```

```python
production_final_test.py
├── Phase 4에서 검증된 최적 설정(PRODUCTION_OPTIMAL) 로드
├── make_env()로 프로덕션 환경 생성 (container:[10,10,10], boxes:12)
├── 최적 설정으로 MaskablePPO 모델 생성 및 학습 (50,000 스텝)
├── 학습된 모델 저장 (models/production_optimal_*.zip)
└── 강화된 평가 (50 에피소드)를 통해 최종 성능 검증 및 결과 저장
```

```plaintext
# 핵심 RL 라이브러리
gymnasium
stable-baselines3
sb3-contrib
torch

# 하이퍼파라미터 최적화
optuna>=3.0.0
wandb>=0.15.0

# 시각화 및 분석
matplotlib
plotly>=5.0.0
scikit-learn>=1.0.0

# 기타 유틸리티
numpy
tensorboard
tqdm
rich
```

```plaintext
RL-3DbinPacking/
├── enhanced_optimization.py          # Phase 4 최적화 스크립트
├── production_final_test.py          # 프로덕션 최종 테스트
├── requirements.txt                  # 의존성 정의
├── src/                             # 핵심 모듈
│   ├── train_maskable_ppo.py        # 학습/환경 생성 엔진
│   ├── packing_env.py               # Gymnasium 환경 정의
│   ├── packing_kernel.py            # 핵심 패킹 로직
│   ├── utils.py                     # 박스 생성 및 유틸리티
│   └── device_utils.py              # 장치 설정
├── results/                         # 실행 결과
│   ├── phase4_enhanced_all_*.json   # 최적화 결과 데이터
│   └── phase4_enhanced_all_*.png    # 성능 분석 그래프
└── models/                          # 학습된 모델
    └── production_optimal_*.zip     # 최종 검증 모델
```

```shellscript
# Phase 4 전체 최적화 실행 (약 4~5시간 소요)
python enhanced_optimization.py --focus=all --timesteps=50000
```

```shellscript
# 프로덕션 최종 검증 (완전 테스트, 약 4~5시간 소요)
python production_final_test.py

# 빠른 검증 (약 2~3시간 소요)
python production_final_test.py --quick
```

