#!/usr/bin/env python3
"""
ğŸ”¬ ì²´ê³„ì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬íƒìƒ‰
ì¬í˜„ì„± í™•ë³´ + í™•ì¥ëœ ë²”ìœ„ íƒìƒ‰
"""

import os
import sys
import warnings
import datetime
import time
import json
import numpy as np

os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'
warnings.filterwarnings("ignore")
sys.path.append('src')

print("ğŸ”¬ ì²´ê³„ì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬íƒìƒ‰")

# ğŸ† ì´ì „ ìµœê³  ì„±ëŠ¥ íŒŒë¼ë¯¸í„° (ì¬í˜„ ê¸°ì¤€ì )
BASELINE_BEST = {
    'learning_rate': 2e-4,
    'n_steps': 512,
    'batch_size': 64,
    'n_epochs': 3,
    'clip_range': 0.17716239549317803,
    'ent_coef': 0.06742268917730829,
    'vf_coef': 0.4545305173856873,
    'gae_lambda': 0.9449228658070746
}

def create_environment(container_size, num_boxes, seed):
    """í™˜ê²½ ìƒì„± (ì™„ì „íˆ ë™ì¼í•œ ë°©ì‹)"""
    try:
        import gymnasium as gym
        from gymnasium.envs.registration import register
        from packing_env import PackingEnv
        from utils import boxes_generator
        
        if 'PackingEnv-v0' not in gym.envs.registry:
            register(id='PackingEnv-v0', entry_point='packing_env:PackingEnv')
        
        box_sizes = boxes_generator(container_size, num_boxes, seed)
        env = gym.make(
            "PackingEnv-v0",
            container_size=container_size,
            box_sizes=box_sizes,
            num_visible_boxes=min(3, num_boxes),
            render_mode=None,
            random_boxes=False,
            only_terminal_reward=False,
        )
        
        try:
            from train_maskable_ppo import ImprovedRewardWrapper
            env = ImprovedRewardWrapper(env)
        except:
            pass
        
        from sb3_contrib.common.wrappers import ActionMasker
        
        def get_masks(env):
            try:
                from train_maskable_ppo import get_action_masks
                return get_action_masks(env)
            except:
                import numpy as np
                return np.ones(env.action_space.n, dtype=bool)
        
        env = ActionMasker(env, get_masks)
        return env
        
    except Exception as e:
        print(f"âŒ í™˜ê²½ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def train_and_evaluate(params, container_size, num_boxes, train_steps, name=""):
    """í•™ìŠµ ë° í‰ê°€ (ì™„ì „íˆ í†µì œëœ ë°©ì‹)"""
    try:
        print(f"\nğŸ“ {name} í•™ìŠµ ì¤‘...")
        print(f"   LR: {params['learning_rate']:.2e}")
        print(f"   Steps: {params['n_steps']}, Batch: {params['batch_size']}")
        
        # === í™˜ê²½ ìƒì„± ===
        env = create_environment(container_size, num_boxes, 42)  # ê³ ì • ì‹œë“œ
        if env is None:
            return 0.0
        
        # === ëª¨ë¸ ìƒì„± ===
        import torch
        torch.set_default_dtype(torch.float32)
        torch.set_num_threads(2)
        
        from sb3_contrib import MaskablePPO
        import torch.nn as nn
        
        model = MaskablePPO(
            "MultiInputPolicy",
            env,
            learning_rate=params['learning_rate'],
            n_steps=params['n_steps'],
            batch_size=params['batch_size'],
            n_epochs=params['n_epochs'],
            gamma=0.99,
            gae_lambda=params['gae_lambda'],
            clip_range=params['clip_range'],
            ent_coef=params['ent_coef'],
            vf_coef=params['vf_coef'],
            max_grad_norm=0.5,
            verbose=0,
            device='cpu',
            policy_kwargs=dict(
                net_arch=[128, 128],
                activation_fn=nn.ReLU,
            )
        )
        
        # === ì¶©ë¶„í•œ í•™ìŠµ ì‹œê°„ ===
        start_time = time.time()
        model.learn(total_timesteps=train_steps, progress_bar=False)
        training_time = time.time() - start_time
        
        print(f"   â±ï¸ í•™ìŠµ ì™„ë£Œ: {training_time:.1f}ì´ˆ")
        
        # === ì•ˆì •ì  í‰ê°€ (ë” ë§ì€ ì—í”¼ì†Œë“œ) ===
        all_rewards, all_utils = [], []
        
        for ep in range(15):  # ë” ë§ì€ í‰ê°€ ì—í”¼ì†Œë“œ
            eval_env = create_environment(container_size, num_boxes, 100 + ep * 17)
            if eval_env is None: continue
            
            obs, _ = eval_env.reset(seed=100 + ep * 17)
            episode_reward = 0.0
            
            for step in range(25):
                try:
                    action, _ = model.predict(obs, deterministic=False)
                    obs, reward, terminated, truncated, info = eval_env.step(action)
                    episode_reward += reward
                    
                    if terminated or truncated:
                        break
                except:
                    break
            
            # í™œìš©ë¥  ê³„ì‚°
            utilization = 0.0
            try:
                if hasattr(eval_env.unwrapped, 'container'):
                    placed_volume = sum(box.volume for box in eval_env.unwrapped.container.boxes 
                                      if box.position is not None)
                    container_volume = eval_env.unwrapped.container.volume
                    utilization = placed_volume / container_volume if container_volume > 0 else 0.0
            except:
                pass
            
            all_rewards.append(episode_reward)
            all_utils.append(utilization)
            eval_env.close()
        
        env.close()
        del model
        
        if not all_rewards:
            return 0.0
        
        # === ì¢…í•© ì ìˆ˜ ê³„ì‚° ===
        mean_reward = np.mean(all_rewards)
        mean_util = np.mean(all_utils)
        combined_score = mean_reward * 0.3 + mean_util * 100 * 0.7
        
        print(f"   ğŸ“Š ê²°ê³¼: ë³´ìƒ={mean_reward:.3f}, í™œìš©ë¥ ={mean_util:.1%}, ì ìˆ˜={combined_score:.2f}")
        
        return combined_score
        
    except Exception as e:
        print(f"âŒ {name} ì‹¤íŒ¨: {e}")
        return 0.0

def systematic_search():
    """ì²´ê³„ì  íƒìƒ‰ ì‹¤í–‰"""
    try:
        print("\nğŸ¯ ì‹¤í—˜ ì„¤ì •:")
        container_size = [8, 8, 8]  # ì´ì „ê³¼ ë™ì¼
        num_boxes = 6              # ì´ì „ê³¼ ë™ì¼
        train_steps = 12000        # ë” ê¸´ í•™ìŠµ ì‹œê°„
        
        print(f"   - ì»¨í…Œì´ë„ˆ: {container_size}")
        print(f"   - ë°•ìŠ¤ ê°œìˆ˜: {num_boxes}")
        print(f"   - í•™ìŠµ ìŠ¤í…: {train_steps:,}")
        
        results = {}
        
        # === 1. ê¸°ì¤€ì  ì¬í˜„ í…ŒìŠ¤íŠ¸ ===
        print(f"\nğŸ† === ê¸°ì¤€ì  ì¬í˜„ í…ŒìŠ¤íŠ¸ ===")
        baseline_score = train_and_evaluate(
            BASELINE_BEST, container_size, num_boxes, train_steps, "ê¸°ì¤€ì "
        )
        results['baseline_reproduction'] = {
            'params': BASELINE_BEST,
            'score': baseline_score
        }
        
        # === 2. í™•ì¥ëœ í•™ìŠµë¥  íƒìƒ‰ ===
        print(f"\nğŸ” === í™•ì¥ëœ í•™ìŠµë¥  íƒìƒ‰ ===")
        
        # ğŸ¯ ë” ë„“ì€ í•™ìŠµë¥  ë²”ìœ„ (ê¸°ì¡´ì˜ 3ë°° í™•ì¥)
        learning_rates = [
            1.2e-4, 1.5e-4, 1.8e-4,  # ë” ë‚®ì€ ì˜ì—­
            2.0e-4,                   # ê¸°ì¤€ì 
            2.2e-4, 2.5e-4, 2.8e-4,  # ë” ë†’ì€ ì˜ì—­
            3.2e-4, 3.5e-4           # í›¨ì”¬ ë†’ì€ ì˜ì—­
        ]
        
        best_lr_score = 0
        best_lr = None
        
        for lr in learning_rates:
            lr_params = BASELINE_BEST.copy()
            lr_params['learning_rate'] = lr
            
            score = train_and_evaluate(
                lr_params, container_size, num_boxes, train_steps, f"LR={lr:.2e}"
            )
            
            results[f'lr_{lr:.2e}'] = {'params': lr_params, 'score': score}
            
            if score > best_lr_score:
                best_lr_score = score
                best_lr = lr
        
        # === 3. ìµœì  í•™ìŠµë¥  ê¸°ë°˜ ë¯¸ì„¸ ì¡°ì • ===
        if best_lr and best_lr_score > baseline_score:
            print(f"\nğŸš€ === ìµœì  í•™ìŠµë¥ ({best_lr:.2e}) ê¸°ë°˜ ë¯¸ì„¸ ì¡°ì • ===")
            
            # n_epochs ì¡°ì •
            for n_epochs in [3, 4, 5]:
                params = BASELINE_BEST.copy()
                params['learning_rate'] = best_lr
                params['n_epochs'] = n_epochs
                
                score = train_and_evaluate(
                    params, container_size, num_boxes, train_steps, 
                    f"ìµœì LR+Epochs={n_epochs}"
                )
                
                results[f'optimal_lr_epochs_{n_epochs}'] = {'params': params, 'score': score}
            
            # batch_size ì¡°ì •
            for batch_size in [48, 64, 96]:
                params = BASELINE_BEST.copy()
                params['learning_rate'] = best_lr
                params['batch_size'] = batch_size
                
                score = train_and_evaluate(
                    params, container_size, num_boxes, train_steps, 
                    f"ìµœì LR+Batch={batch_size}"
                )
                
                results[f'optimal_lr_batch_{batch_size}'] = {'params': params, 'score': score}
        
        # === 4. ê²°ê³¼ ë¶„ì„ ===
        print(f"\nğŸ“ˆ === ìµœì¢… ê²°ê³¼ ë¶„ì„ ===")
        
        best_overall_score = 0
        best_overall_config = None
        best_overall_name = ""
        
        print(f"{'ì„¤ì •':<25} {'ì ìˆ˜':<8} {'ê°œì„ ìœ¨':<8}")
        print("-" * 45)
        
        for name, data in results.items():
            score = data['score']
            improvement = ((score - 18.57) / 18.57) * 100 if score > 0 else -100
            
            print(f"{name:<25} {score:<8.2f} {improvement:<+7.1f}%")
            
            if score > best_overall_score:
                best_overall_score = score
                best_overall_config = data['params']
                best_overall_name = name
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_overall_name} (ì ìˆ˜: {best_overall_score:.2f})")
        
        # === 5. ê²°ê³¼ ì €ì¥ ===
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"results/systematic_search_{timestamp}.json"
        
        os.makedirs('results', exist_ok=True)
        
        final_data = {
            'timestamp': timestamp,
            'search_type': 'systematic_reproduction_and_expansion',
            'experiment_config': {
                'container_size': container_size,
                'num_boxes': num_boxes,
                'train_steps': train_steps
            },
            'baseline_target': 18.57,
            'baseline_reproduction': baseline_score,
            'best_config': best_overall_name,
            'best_score': best_overall_score,
            'best_params': best_overall_config,
            'improvement_from_target': ((best_overall_score - 18.57) / 18.57) * 100,
            'all_results': results
        }
        
        with open(results_file, 'w') as f:
            json.dump(final_data, f, indent=2)
        
        print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_file}")
        
        # === 6. ê¶Œì¥ì‚¬í•­ ===
        if best_overall_score > 18.57:
            print(f"\nğŸ‰ ì„±ëŠ¥ ê°œì„  ì„±ê³µ!")
            print(f"ğŸ’¡ ê¶Œì¥ íŒŒë¼ë¯¸í„°:")
            for key, value in best_overall_config.items():
                if key == 'learning_rate':
                    print(f"   {key}: {value:.2e}")
                else:
                    print(f"   {key}: {value}")
        else:
            print(f"\nğŸ“Š ì¶”ê°€ ë¶„ì„ í•„ìš”:")
            print(f"   ê¸°ì¤€ì  ì¬í˜„: {baseline_score:.2f}")
            print(f"   ìµœê³  ì ìˆ˜: {best_overall_score:.2f}")
            if baseline_score < 16.0:
                print(f"   âš ï¸ ê¸°ì¤€ì  ì¬í˜„ ì‹¤íŒ¨ - í™˜ê²½ ì„¤ì • ì ê²€ í•„ìš”")
            else:
                print(f"   ğŸ’¡ ë” ê¸´ í•™ìŠµ ì‹œê°„ì´ë‚˜ ë‹¤ë¥¸ ì ‘ê·¼ í•„ìš”")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì²´ê³„ì  íƒìƒ‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ”¬ ì²´ê³„ì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬íƒìƒ‰")
    print(f"ğŸš€ Python: {sys.version}")
    print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
    
    success = systematic_search()
    
    if success:
        print(f"\nğŸ‰ ì²´ê³„ì  íƒìƒ‰ ì™„ë£Œ!")
        print(f"ğŸ”¬ ì¬í˜„ì„±ê³¼ ìµœì í™”ê°€ ë™ì‹œì— ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"\nâŒ íƒìƒ‰ ì‹¤íŒ¨")