# 실시간 모니터링 기능 사용 가이드

## 🚀 개요

Maskable PPO 3D Bin Packing 학습 과정에서 **실시간으로 성능 지표를 모니터링**할 수 있는 기능이 대폭 강화되었습니다! 이제 **활용률과 안정성 지표까지 포함**하여 학습 진행 상황을 종합적으로 실시간 확인할 수 있습니다.

## 📊 주요 기능 (업데이트!)

### 🆕 새로 추가된 기능들

#### 1. **컨테이너 활용률 실시간 추적**
- **에피소드별 활용률**: 각 에피소드에서 달성한 컨테이너 공간 활용률
- **평가 활용률**: 주기적 평가 시 활용률 성능
- **최대 활용률 기록**: 지금까지 달성한 최고 활용률 추적
- **목표선 표시**: 80% 목표 활용률 기준선

#### 2. **학습 안정성 지표**
- **보상 안정성**: 최근 에피소드들의 보상 표준편차
- **활용률 안정성**: 활용률의 변동성 측정
- **학습 smoothness**: 학습 곡선의 부드러움 정도 (0~1)

#### 3. **더 빈번한 실시간 업데이트**
- **빠른 업데이트**: 1000 스텝마다 주요 차트 업데이트
- **전체 업데이트**: 기존 주기로 모든 차트 종합 업데이트

### 📈 6개 차트 종합 대시보드

1. **상단 왼쪽**: 에피소드별 보상 (이동평균 포함)
2. **상단 오른쪽**: 컨테이너 활용률 (목표선 포함)
3. **중단 왼쪽**: 평가 성능 (보상 & 활용률)
4. **중단 오른쪽**: 성공률 (목표선 포함)
5. **하단 왼쪽**: 학습 안정성 지표
6. **하단 오른쪽**: 에피소드 길이 & 최대 활용률

## 🛠️ 사용 방법

### 기본 학습 (강화된 실시간 모니터링)

```bash
# 기본 실행 - 종합 모니터링 활성화
python -m src.train_maskable_ppo --timesteps 100000

# 더 자주 업데이트하는 실시간 모니터링
python -m src.train_maskable_ppo --timesteps 50000 --eval-freq 5000

# CPU 환경에서 실행
python -m src.train_maskable_ppo --timesteps 30000 --force-cpu
```

### 학습 중 실시간 출력 예시

```
스텝: 25,000 | 에피소드: 156 | 최근 10 에피소드 평균 보상: 0.642 | 평균 활용률: 64.2% | 최대 활용률: 78.5% | 경과 시간: 180.5초

평가 수행 중... (스텝: 25,000)
평가 완료: 평균 보상 0.685, 평균 활용률 68.5%, 성공률 80.0%
```

### 학습 통계 분석 (확장된 기능)

```bash
# 종합 분석 (활용률 & 안정성 포함)
python -m src.train_maskable_ppo --analyze-only results/comprehensive_training_stats_20241201_143022.npy

# 종합 대시보드 생성
python -m src.train_maskable_ppo --dashboard-only results/comprehensive_training_stats_20241201_143022.npy
```

## 📈 차트별 상세 해석

### 🎯 활용률 차트 (상단 오른쪽)
- **초록색 선**: 에피소드별 활용률
- **진한 초록색 선**: 활용률 이동평균
- **주황색 점선**: 80% 목표선
- **목표**: 꾸준히 80% 이상 달성

### ⚖️ 학습 안정성 차트 (하단 왼쪽)
- **빨간색 선**: 보상 안정성 (낮을수록 안정적)
- **파란색 선**: 활용률 안정성 (낮을수록 안정적)  
- **초록색 선**: 학습 smoothness (높을수록 부드러운 학습)

### 📊 평가 성능 차트 (중단 왼쪽)
- **왼쪽 축**: 평가 보상 (초록색)
- **오른쪽 축**: 평가 활용률 (보라색)
- **해석**: 두 지표 모두 상승 추세여야 함

### 🎖️ 최대 활용률 추적 (하단 오른쪽)
- **왼쪽 축**: 에피소드 길이 (보라색)
- **오른쪽 축**: 최대 활용률 (주황색 별표)
- **해석**: 최대 활용률이 지속적으로 갱신되어야 함

## 🎯 성과 분석 지표 (확장됨)

### 📈 기본 성과 지표
- 총 에피소드 수 & 학습 스텝
- 최종/최고 평가 보상
- 최종/최고 성공률

### 🎯 활용률 성과 지표 (신규!)
- **최종 활용률**: 학습 마지막 에피소드 활용률
- **최고 활용률**: 전체 학습 중 달성한 최고 활용률
- **평균 활용률**: 전체 에피소드 평균 활용률
- **최종 평가 활용률**: 마지막 평가에서의 활용률
- **최고 평가 활용률**: 평가 중 달성한 최고 활용률

### ⚖️ 학습 안정성 지표 (신규!)
- **최종 보상 안정성**: 학습 후반부 보상 안정성
- **최종 활용률 안정성**: 학습 후반부 활용률 안정성  
- **최종 학습 smoothness**: 전체 학습의 부드러움
- **평균 안정성 지표들**: 전 구간 평균 안정성

### 🏆 자동 등급 평가
- **활용률**: 🥇 우수(80%+) / 🥈 양호(60-80%) / 🥉 개선필요(60%-)
- **성공률**: 🥇 우수(80%+) / 🥈 양호(50-80%) / 🥉 개선필요(50%-)
- **학습 안정성**: 🥇 매우안정적(0.7+) / 🥈 안정적(0.5-0.7) / 🥉 불안정(0.5-)

## 📁 출력 파일 (확장됨)

### 자동 생성되는 파일들

```
results/
├── comprehensive_training_progress_YYYYMMDD_HHMMSS.png     # 6개 차트 종합 대시보드
├── comprehensive_training_stats_YYYYMMDD_HHMMSS.npy       # 종합 학습 통계 (활용률+안정성)
├── comprehensive_summary_YYYYMMDD_HHMMSS.txt              # 한글 성과 요약 보고서
├── training_results_YYYYMMDD_HHMMSS.txt                   # 기본 결과 요약
└── final_dashboard_YYYYMMDD_HHMMSS.png                    # 최종 대시보드
```

### 📋 성과 요약 보고서 예시

```
=== 종합 학습 성과 요약 ===

📈 기본 성과 지표:
  • 총 에피소드: 1,523
  • 총 학습 스텝: 100,000
  • 최종 평가 보상: 0.742
  • 최고 평가 보상: 0.856
  • 최종 성공률: 85.0%
  • 최고 성공률: 90.0%

🎯 활용률 성과:
  • 최종 활용률: 74.2%
  • 최고 활용률: 85.6%
  • 평균 활용률: 68.3%
  • 최종 평가 활용률: 78.1%
  • 최고 평가 활용률: 85.6%

⚖️ 학습 안정성:
  • 최종 보상 안정성: 0.082
  • 최종 활용률 안정성: 0.075
  • 최종 학습 smoothness: 0.742
  • 평균 보상 안정성: 0.095
  • 평균 활용률 안정성: 0.088
  • 평균 학습 smoothness: 0.685

🏆 성과 등급:
  • 활용률: 🥇 우수 (80% 이상)
  • 성공률: 🥇 우수 (80% 이상)
  • 학습 안정성: 🥈 안정적
```

## 🔧 고급 설정

### 모니터링 주기 세밀 조정

```python
# train_maskable_ppo.py 수정
monitor_callback = RealTimeMonitorCallback(
    eval_env=eval_env,
    eval_freq=3000,        # 3000 스텝마다 평가
    n_eval_episodes=8,     # 평가 에피소드 수 증가
    verbose=1,
    update_freq=500        # 500 스텝마다 빠른 업데이트
)
```

### 활용률 목표 조정

```python
# _update_plots 함수에서 목표선 수정
self.axes[0, 1].axhline(y=90, color='red', linestyle='--', alpha=0.7, label='높은목표(90%)')
```

## 💡 실시간 모니터링 팁

### 🎯 활용률 개선 전략
1. **60% 미만**: 기본 학습 파라미터 점검
2. **60-80%**: 보상 함수 미세 조정
3. **80% 이상**: 안정성 향상에 집중

### ⚖️ 안정성 해석 가이드
- **보상 안정성 < 0.1**: 매우 안정적인 학습
- **활용률 안정성 < 0.08**: 일관된 성능 향상
- **학습 smoothness > 0.7**: 부드러운 학습 곡선

### 📈 실시간 대응 전략
- **활용률 정체**: 탐험률 조정 고려
- **안정성 악화**: 학습률 감소 검토
- **평가 성능 하락**: 조기 중단 고려

## 🚨 문제 해결

### 메모리 사용량이 많을 때
```bash
# 업데이트 주기 늘리기
python -m src.train_maskable_ppo --timesteps 50000 --eval-freq 15000
```

### 차트가 너무 복잡할 때
```python
# _quick_update_plots에서 주요 차트만 활성화
if len(self.episode_rewards) > 10:
    # 보상과 활용률만 업데이트
    self._update_reward_chart()
    self._update_utilization_chart()
```

## 📚 실제 사용 시나리오

### 1. 빠른 성능 확인 (10분)
```bash
python -m src.train_maskable_ppo --timesteps 10000 --eval-freq 2000
```

### 2. 본격 학습 모니터링 (2시간)
```bash
python -m src.train_maskable_ppo --timesteps 150000 --eval-freq 7500
```

### 3. 장기 안정성 테스트 (하룻밤)
```bash
nohup python -m src.train_maskable_ppo --timesteps 500000 --eval-freq 12500 > training.log 2>&1 &
```

### 4. 성과 비교 분석
```bash
# 여러 실험 결과 비교
python -m src.train_maskable_ppo --analyze-only results/comprehensive_training_stats_20241201_143022.npy
python -m src.train_maskable_ppo --analyze-only results/comprehensive_training_stats_20241201_183045.npy
```

---

🎉 **이제 활용률과 안정성까지 포함한 종합적인 실시간 모니터링을 통해 더욱 효과적인 3D Bin Packing 학습이 가능합니다!**

📧 **문의사항이나 개선 제안은 언제든지 이슈로 등록해 주세요!** 