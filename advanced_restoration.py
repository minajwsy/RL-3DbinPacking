#!/usr/bin/env python3
"""
ğŸ¯ ì„±ëŠ¥ ë³µì› ì¤‘ì‹¬ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
ì´ì „ 17.89ì  ì„±ëŠ¥ì„ ë³µì›í•˜ê³  ëª©í‘œ 18.57ì  ë‹¬ì„±
"""

import os
import sys
import warnings
import datetime
import time
import json
import argparse
import numpy as np
from typing import Dict, Any, List, Tuple, Optional

# í™˜ê²½ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'
warnings.filterwarnings("ignore")
sys.path.append('src')

print("ğŸ¯ ì„±ëŠ¥ ë³µì› ì¤‘ì‹¬ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸")

# === í•µì‹¬ ê°œì„ ì‚¬í•­ ===
PERFORMANCE_RESTORATION_CONFIG = {
    # 1. í•™ìŠµ ì‹œê°„ ëŒ€í­ ì¦ê°€
    'base_timesteps': 15000,      # ì´ì „: 8000 â†’ ê°œì„ : 15000
    'extended_timesteps': 25000,  # ìµœì¢… ê²€ì¦ìš©
    
    # 2. í‰ê°€ ê°•í™”
    'eval_episodes': 25,         # ì´ì „: 12 â†’ ê°œì„ : 25
    'max_steps_per_episode': 50, # ì´ì „: 25 â†’ ê°œì„ : 50
    
    # 3. ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ìµœì í™”
    'network_architectures': [
        [128, 128],        # ê¸°ë³¸
        [256, 256],        # í™•ì¥
        [256, 128, 64],    # ì ì§„ì 
        [512, 256],        # ëŒ€í˜•
    ],
    
    # 4. ë‹¤ë‹¨ê³„ ë³µì¡ë„
    'complexity_levels': [
        ([8, 8, 8], 6),    # 1ë‹¨ê³„: í˜„ì¬ ì„¤ì •
        ([8, 8, 8], 8),    # 2ë‹¨ê³„: ë°•ìŠ¤ ì¦ê°€
        ([10, 10, 10], 8), # 3ë‹¨ê³„: ì»¨í…Œì´ë„ˆ í™•ì¥
        ([10, 10, 10], 12), # 4ë‹¨ê³„: ëª©í‘œ ì„¤ì •
    ]
}

# === ì´ì „ ì„±ê³µ ê¸°ë°˜ ìµœì  íŒŒë¼ë¯¸í„° ===
RESTORATION_OPTIMAL = {
    'learning_rate': 2.5e-4,     # ì´ì „ ìµœì ê°’
    'n_steps': 512,              # ì´ì „ ìµœì ê°’
    'batch_size': 64,            # ì´ì „ ìµœì ê°’
    'n_epochs': 4,               # ì•½ê°„ ì¦ê°€
    'clip_range': 0.2,           # í‘œì¤€ê°’
    'ent_coef': 0.01,            # í‘œì¤€ê°’
    'vf_coef': 0.5,              # í‘œì¤€ê°’
    'gae_lambda': 0.95,          # í‘œì¤€ê°’
    'net_arch': [256, 256],      # ë” í° ë„¤íŠ¸ì›Œí¬
}

# === ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„ ===
ADVANCED_PARAM_RANGES = {
    'learning_rate': [1.5e-4, 2.0e-4, 2.5e-4, 3.0e-4, 3.5e-4],
    'n_steps': [512, 1024, 2048],
    'batch_size': [64, 128, 256],
    'n_epochs': [3, 4, 5, 6],
    'net_arch': [[128, 128], [256, 256], [256, 128, 64]],
}

def create_environment(container_size, num_boxes, seed=42):
    """ê°œì„ ëœ í™˜ê²½ ìƒì„±"""
    try:
        import gymnasium as gym
        from stable_baselines3.common.monitor import Monitor
        from sb3_contrib.common.wrappers import ActionMasker
        from src.train_maskable_ppo import make_env
        
        # í™˜ê²½ ìƒì„±
        env = make_env(
            container_size=container_size,
            num_boxes=num_boxes,
            num_visible_boxes=3,
            seed=seed,
            render_mode=None,
            random_boxes=False,
            only_terminal_reward=False,
            improved_reward_shaping=True,
        )()
        
        print(f"âœ… í™˜ê²½ ìƒì„± ì„±ê³µ: ì»¨í…Œì´ë„ˆ{container_size}, ë°•ìŠ¤{num_boxes}ê°œ")
        return env
        
    except Exception as e:
        print(f"âŒ í™˜ê²½ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def train_model(env, params, train_steps=15000, name="", net_arch=None):
    """ê°œì„ ëœ ëª¨ë¸ í•™ìŠµ"""
    try:
        import torch
        import torch.nn as nn
        from sb3_contrib import MaskablePPO
        
        if net_arch is None:
            net_arch = params.get('net_arch', [256, 256])
        
        print(f"ğŸ“ {name} í•™ìŠµ ì‹œì‘: {train_steps:,} ìŠ¤í… (LR: {params['learning_rate']:.2e}, Net: {net_arch})")
        
        start_time = time.time()
        
        # ëª¨ë¸ ìƒì„±
        model = MaskablePPO(
            "MultiInputPolicy",
            env,
            learning_rate=params['learning_rate'],
            n_steps=params['n_steps'],
            batch_size=params['batch_size'],
            n_epochs=params['n_epochs'],
            gamma=0.99,
            gae_lambda=params['gae_lambda'],
            clip_range=params['clip_range'],
            ent_coef=params['ent_coef'],
            vf_coef=params['vf_coef'],
            max_grad_norm=0.5,
            verbose=0,
            seed=42,
            policy_kwargs=dict(
                net_arch=net_arch,
                activation_fn=nn.ReLU,
                share_features_extractor=True,
            )
        )
        
        # í•™ìŠµ ì‹¤í–‰
        model.learn(total_timesteps=train_steps, progress_bar=False)
        
        duration = time.time() - start_time
        print(f"â±ï¸ {name} í•™ìŠµ ì™„ë£Œ: {duration:.1f}ì´ˆ")
        
        return model, duration
        
    except Exception as e:
        print(f"âŒ {name} ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
        return None, 0

def evaluate_model(model, container_size, num_boxes, n_episodes=25, max_steps=50, name=""):
    """ê°•í™”ëœ ëª¨ë¸ í‰ê°€"""
    try:
        print(f"ğŸ” {name} í‰ê°€ ì‹œì‘ ({n_episodes} ì—í”¼ì†Œë“œ, ìµœëŒ€ {max_steps} ìŠ¤í…)")
        
        all_rewards = []
        all_utilizations = []
        placement_counts = []
        success_count = 0
        
        for ep in range(n_episodes):
            seed = 100 + ep * 5
            eval_env = create_environment(container_size, num_boxes, seed)
            
            if eval_env is None:
                continue
            
            obs, _ = eval_env.reset(seed=seed)
            episode_reward = 0.0
            
            for step in range(max_steps):
                try:
                    action, _ = model.predict(obs, deterministic=False)
                    obs, reward, terminated, truncated, info = eval_env.step(action)
                    episode_reward += reward
                    
                    if terminated or truncated:
                        break
                        
                except Exception as e:
                    break
            
            # í™œìš©ë¥  ë° ë°°ì¹˜ ë°•ìŠ¤ ê³„ì‚°
            utilization = 0.0
            placed_boxes = 0
            try:
                if hasattr(eval_env.unwrapped, 'container'):
                    placed_volume = sum(box.volume for box in eval_env.unwrapped.container.boxes 
                                      if box.position is not None)
                    container_volume = eval_env.unwrapped.container.volume
                    utilization = placed_volume / container_volume if container_volume > 0 else 0.0
                    placed_boxes = sum(1 for box in eval_env.unwrapped.container.boxes 
                                     if box.position is not None)
            except:
                pass
            
            # ì„±ê³µ ê¸°ì¤€: í™œìš©ë¥  30% ì´ìƒ ë˜ëŠ” ë°•ìŠ¤ 50% ì´ìƒ ë°°ì¹˜
            if utilization >= 0.3 or placed_boxes >= num_boxes * 0.5:
                success_count += 1
            
            all_rewards.append(episode_reward)
            all_utilizations.append(utilization)
            placement_counts.append(placed_boxes)
            
            if ep < 5 or ep % 5 == 0:  # ì²˜ìŒ 5ê°œì™€ 5ì˜ ë°°ìˆ˜ë§Œ ì¶œë ¥
                print(f"   ì—í”¼ì†Œë“œ {ep+1}: ë³´ìƒ={episode_reward:.3f}, í™œìš©ë¥ ={utilization:.1%}, ë°•ìŠ¤={placed_boxes}ê°œ")
            
            eval_env.close()
        
        if not all_rewards:
            return None
        
        results = {
            'mean_reward': np.mean(all_rewards),
            'std_reward': np.std(all_rewards),
            'mean_utilization': np.mean(all_utilizations),
            'std_utilization': np.std(all_utilizations),
            'mean_placement': np.mean(placement_counts),
            'max_placement': max(placement_counts),
            'success_rate': success_count / len(all_rewards),
            'combined_score': np.mean(all_rewards) * 0.3 + np.mean(all_utilizations) * 100 * 0.7,
            'episodes': len(all_rewards)
        }
        
        print(f"ğŸ“Š {name} ìµœì¢… ê²°ê³¼:")
        print(f"   í‰ê·  ë³´ìƒ: {results['mean_reward']:.3f} Â± {results['std_reward']:.3f}")
        print(f"   í‰ê·  í™œìš©ë¥ : {results['mean_utilization']:.1%} Â± {results['std_utilization']:.1%}")
        print(f"   í‰ê·  ë°°ì¹˜: {results['mean_placement']:.1f}ê°œ (ìµœëŒ€: {results['max_placement']}ê°œ)")
        print(f"   ì„±ê³µë¥ : {results['success_rate']:.1%}")
        print(f"   ì¢…í•© ì ìˆ˜: {results['combined_score']:.3f}")
        
        return results
        
    except Exception as e:
        print(f"âŒ {name} í‰ê°€ ì˜¤ë¥˜: {e}")
        return None

def phase_restore():
    """Phase 1: ì„±ëŠ¥ ë³µì› - ì´ì „ ì„±ê³µ ì„¤ì • ì™„ì „ ì¬í˜„"""
    print("\n" + "="*60)
    print("ğŸ¯ Phase 1: ì„±ëŠ¥ ë³µì› (ì´ì „ 17.89ì  ì„±ëŠ¥ ì¬í˜„)")
    print("="*60)
    
    # ê¸°ë³¸ ì„¤ì •
    container_size = [8, 8, 8]
    num_boxes = 6
    train_steps = PERFORMANCE_RESTORATION_CONFIG['base_timesteps']
    
    print(f"ğŸ“‹ ì„¤ì •: ì»¨í…Œì´ë„ˆ{container_size}, ë°•ìŠ¤{num_boxes}ê°œ, {train_steps:,}ìŠ¤í…")
    
    results = {}
    
    # === 1. ê¸°ì¤€ì  ì¬í˜„ (ì´ì „ ìµœì  íŒŒë¼ë¯¸í„°) ===
    print(f"\nğŸ† ì´ì „ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì„±ëŠ¥ ë³µì› ì‹œë„")
    
    env1 = create_environment(container_size, num_boxes, 42)
    if env1:
        model1, time1 = train_model(env1, RESTORATION_OPTIMAL, train_steps, "ë³µì›", [256, 256])
        if model1:
            results['restoration_256'] = evaluate_model(
                model1, container_size, num_boxes, 
                PERFORMANCE_RESTORATION_CONFIG['eval_episodes'],
                PERFORMANCE_RESTORATION_CONFIG['max_steps_per_episode'],
                "ë³µì›[256,256]"
            )
            results['restoration_256']['training_time'] = time1
            results['restoration_256']['params'] = RESTORATION_OPTIMAL.copy()
        env1.close()
        del model1
    
    # === 2. ë„¤íŠ¸ì›Œí¬ í¬ê¸° ìµœì í™” ===
    print(f"\nğŸ—ï¸ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ìµœì í™”")
    
    best_score = 0
    best_arch = None
    
    for arch in [[128, 128], [256, 256], [256, 128, 64], [512, 256]]:
        print(f"\nğŸ”§ ì•„í‚¤í…ì²˜ {arch} í…ŒìŠ¤íŠ¸")
        
        env2 = create_environment(container_size, num_boxes, 42)
        if env2:
            model2, time2 = train_model(env2, RESTORATION_OPTIMAL, train_steps, f"Net{arch}", arch)
            if model2:
                result = evaluate_model(
                    model2, container_size, num_boxes,
                    20,  # ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸ëŠ” ì•½ê°„ ì ì€ ì—í”¼ì†Œë“œ
                    PERFORMANCE_RESTORATION_CONFIG['max_steps_per_episode'],
                    f"Net{arch}"
                )
                if result and result['combined_score'] > best_score:
                    best_score = result['combined_score']
                    best_arch = arch
                    
                results[f'net_{str(arch).replace(" ", "")}'] = result
                if result:
                    results[f'net_{str(arch).replace(" ", "")}']['training_time'] = time2
            env2.close()
            del model2
    
    # === 3. ìµœì  ë„¤íŠ¸ì›Œí¬ë¡œ ìµœì¢… ê²€ì¦ ===
    if best_arch:
        print(f"\nğŸš€ ìµœì  ë„¤íŠ¸ì›Œí¬ {best_arch}ë¡œ ìµœì¢… ê²€ì¦")
        
        # ë” ê¸´ í•™ìŠµìœ¼ë¡œ ìµœì¢… í…ŒìŠ¤íŠ¸
        extended_steps = int(train_steps * 1.5)  # 50% ë” ê¸´ í•™ìŠµ
        
        env3 = create_environment(container_size, num_boxes, 42)
        if env3:
            model3, time3 = train_model(env3, RESTORATION_OPTIMAL, extended_steps, f"ìµœì¢…{best_arch}", best_arch)
            if model3:
                results['final_restoration'] = evaluate_model(
                    model3, container_size, num_boxes,
                    PERFORMANCE_RESTORATION_CONFIG['eval_episodes'],
                    PERFORMANCE_RESTORATION_CONFIG['max_steps_per_episode'],
                    f"ìµœì¢…ë³µì›{best_arch}"
                )
                results['final_restoration']['training_time'] = time3
                results['final_restoration']['params'] = RESTORATION_OPTIMAL.copy()
                results['final_restoration']['params']['net_arch'] = best_arch
            env3.close()
            del model3
    
    # === ê²°ê³¼ ì €ì¥ ë° ë¶„ì„ ===
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"results/restoration_phase1_{timestamp}.json"
    
    os.makedirs('results', exist_ok=True)
    with open(results_file, 'w') as f:
        json.dump({
            'timestamp': timestamp,
            'phase': 'restoration',
            'config': {
                'container_size': container_size,
                'num_boxes': num_boxes,
                'train_steps': train_steps
            },
            'target_score': 17.89,
            'results': results
        }, f, indent=2)
    
    # ìµœê³  ì„±ëŠ¥ ì¶œë ¥
    best_result = None
    best_name = ""
    best_final_score = 0
    
    for name, result in results.items():
        if result and result.get('combined_score', 0) > best_final_score:
            best_final_score = result['combined_score']
            best_result = result
            best_name = name
    
    print(f"\n" + "="*60)
    print(f"ğŸ† Phase 1 ë³µì› ê²°ê³¼")
    print(f"="*60)
    print(f"ìµœê³  ì„±ëŠ¥: {best_final_score:.3f}ì  ({best_name})")
    if best_final_score >= 17.0:
        print(f"âœ… ì„±ëŠ¥ ë³µì› ì„±ê³µ! (ëª©í‘œ 17.89 ëŒ€ë¹„ {((best_final_score-17.89)/17.89*100):+.1f}%)")
    else:
        print(f"âš ï¸ ì„±ëŠ¥ ë³µì› ë¶€ë¶„ ì„±ê³µ (ëª©í‘œ 17.89 ëŒ€ë¹„ {((best_final_score-17.89)/17.89*100):+.1f}%)")
    
    print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼: {results_file}")
    
    return results

def phase_expand():
    """Phase 2: ì ì§„ì  í™•ì¥"""
    print("\n" + "="*60)
    print("ğŸ¯ Phase 2: ë³µì¡ë„ ì ì§„ì  í™•ì¥")
    print("="*60)
    
    # Phase 1 ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì  ì„¤ì • ì‚¬ìš©
    base_params = RESTORATION_OPTIMAL.copy()
    base_params['net_arch'] = [256, 256]  # Phase 1ì—ì„œ ê²€ì¦ëœ ì„¤ì •
    
    results = {}
    
    for i, (container_size, num_boxes) in enumerate(PERFORMANCE_RESTORATION_CONFIG['complexity_levels']):
        level_name = f"level_{i+1}"
        print(f"\nğŸš€ ë ˆë²¨ {i+1}: ì»¨í…Œì´ë„ˆ{container_size}, ë°•ìŠ¤{num_boxes}ê°œ")
        
        # ë³µì¡ë„ì— ë”°ë¼ í•™ìŠµ ì‹œê°„ ì¡°ì •
        train_steps = PERFORMANCE_RESTORATION_CONFIG['base_timesteps'] * (1 + i * 0.3)
        train_steps = int(train_steps)
        
        env = create_environment(container_size, num_boxes, 42)
        if env:
            model, train_time = train_model(env, base_params, train_steps, f"ë ˆë²¨{i+1}")
            if model:
                result = evaluate_model(
                    model, container_size, num_boxes,
                    PERFORMANCE_RESTORATION_CONFIG['eval_episodes'],
                    PERFORMANCE_RESTORATION_CONFIG['max_steps_per_episode'],
                    f"ë ˆë²¨{i+1}"
                )
                results[level_name] = result
                if result:
                    results[level_name]['training_time'] = train_time
                    results[level_name]['config'] = {
                        'container_size': container_size,
                        'num_boxes': num_boxes,
                        'train_steps': train_steps
                    }
            env.close()
            del model
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"results/expansion_phase2_{timestamp}.json"
    
    with open(results_file, 'w') as f:
        json.dump({
            'timestamp': timestamp,
            'phase': 'expansion',
            'target_score': 18.57,
            'results': results
        }, f, indent=2)
    
    print(f"ğŸ’¾ Phase 2 ê²°ê³¼: {results_file}")
    return results

def phase_optimize():
    """Phase 3: ëª©í‘œ ë‹¬ì„± ìµœì í™”"""
    print("\n" + "="*60)
    print("ğŸ¯ Phase 3: ëª©í‘œ 18.57ì  ë‹¬ì„± ìµœì í™”")
    print("="*60)
    
    # ìµœì í™” ëŒ€ìƒ ì„¤ì •
    container_size = [10, 10, 10]
    num_boxes = 12
    train_steps = PERFORMANCE_RESTORATION_CONFIG['extended_timesteps']
    
    print(f"ğŸ“‹ ìµœì¢… ëª©í‘œ: ì»¨í…Œì´ë„ˆ{container_size}, ë°•ìŠ¤{num_boxes}ê°œ, {train_steps:,}ìŠ¤í…")
    
    results = {}
    best_score = 0
    best_params = None
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ìµœì í™”
    for lr in ADVANCED_PARAM_RANGES['learning_rate']:
        for batch_size in [64, 128]:
            for net_arch in [[256, 256], [256, 128, 64]]:
                
                params = RESTORATION_OPTIMAL.copy()
                params['learning_rate'] = lr
                params['batch_size'] = batch_size
                params['net_arch'] = net_arch
                
                config_name = f"lr{lr:.1e}_b{batch_size}_net{len(net_arch)}"
                print(f"\nğŸ”§ {config_name} ìµœì í™” ì¤‘...")
                
                env = create_environment(container_size, num_boxes, 42)
                if env:
                    model, train_time = train_model(env, params, train_steps, config_name)
                    if model:
                        result = evaluate_model(
                            model, container_size, num_boxes,
                            PERFORMANCE_RESTORATION_CONFIG['eval_episodes'],
                            PERFORMANCE_RESTORATION_CONFIG['max_steps_per_episode'],
                            config_name
                        )
                        results[config_name] = result
                        if result:
                            results[config_name]['training_time'] = train_time
                            results[config_name]['params'] = params.copy()
                            
                            if result['combined_score'] > best_score:
                                best_score = result['combined_score']
                                best_params = params.copy()
                    env.close()
                    del model
    
    # ê²°ê³¼ ì €ì¥ ë° ë¶„ì„
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"results/optimization_phase3_{timestamp}.json"
    
    with open(results_file, 'w') as f:
        json.dump({
            'timestamp': timestamp,
            'phase': 'optimization',
            'target_score': 18.57,
            'best_score': best_score,
            'best_params': best_params,
            'results': results
        }, f, indent=2)
    
    print(f"\n" + "="*60)
    print(f"ğŸ† Phase 3 ìµœì í™” ê²°ê³¼")
    print(f"="*60)
    print(f"ìµœê³  ì„±ëŠ¥: {best_score:.3f}ì ")
    if best_score >= 18.57:
        print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! ({best_score:.3f} >= 18.57)")
    else:
        print(f"ğŸ“ˆ ëª©í‘œ ê·¼ì ‘ (ëª©í‘œ 18.57 ëŒ€ë¹„ {((best_score-18.57)/18.57*100):+.1f}%)")
    
    print(f"ğŸ’¾ Phase 3 ê²°ê³¼: {results_file}")
    return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ê³ ê¸‰ ì„±ëŠ¥ ë³µì› ìµœì í™”')
    parser.add_argument('--phase', choices=['restore', 'expand', 'optimize'], 
                       default='restore', help='ì‹¤í–‰í•  ë‹¨ê³„')
    parser.add_argument('--timesteps', type=int, help='í•™ìŠµ ìŠ¤í… ìˆ˜ (ì„ íƒì‚¬í•­)')
    parser.add_argument('--complexity', choices=['simple', 'progressive'], 
                       default='progressive', help='ë³µì¡ë„ ì„¤ì •')
    parser.add_argument('--target', type=float, default=18.57, help='ëª©í‘œ ì ìˆ˜')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ ì‹œì‘: Phase {args.phase}")
    print(f"ğŸ“Š Python: {sys.version}")
    print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
    
    start_time = time.time()
    
    try:
        if args.phase == 'restore':
            results = phase_restore()
        elif args.phase == 'expand':
            results = phase_expand()
        elif args.phase == 'optimize':
            results = phase_optimize()
        
        total_time = time.time() - start_time
        print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        print(f"ğŸ‰ Phase {args.phase} ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()