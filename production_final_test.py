#!/usr/bin/env python3
"""
ğŸ† í”„ë¡œë•ì…˜ ìµœì  ì„¤ì • ìµœì¢… ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
Phase 4ì—ì„œ ê²€ì¦ëœ ìµœê³  ì„±ëŠ¥ ì„¤ì • (20.591ì )ìœ¼ë¡œ ìµœì¢… í…ŒìŠ¤íŠ¸
"""

import os
import sys
import json
import time
import numpy as np
from datetime import datetime
import warnings

# í™˜ê²½ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'
warnings.filterwarnings("ignore")
sys.path.append('src')

# ğŸ† ê²€ì¦ëœ ìµœê³  ì„±ëŠ¥ ì„¤ì • (Phase 4 ê²°ê³¼)
PRODUCTION_OPTIMAL = {
    "learning_rate": 0.00013,
    "n_steps": 768,
    "batch_size": 96,
    "n_epochs": 5,
    "clip_range": 0.18,
    "ent_coef": 0.008,
    "vf_coef": 0.5,
    "gae_lambda": 0.96,
    "net_arch": {"pi": [256, 128, 64], "vf": [256, 128, 64]}
}

def create_production_env(container_size=[10, 10, 10], num_boxes=12, seed=42):
    """í”„ë¡œë•ì…˜ í™˜ê²½ ìƒì„±"""
    try:
        from train_maskable_ppo import make_env
        
        env = make_env(
            container_size=container_size,
            num_boxes=num_boxes,
            num_visible_boxes=3,
            seed=seed,
            render_mode=None,
            random_boxes=False,
            only_terminal_reward=False,
            improved_reward_shaping=True,
        )()
        
        print(f"âœ… í”„ë¡œë•ì…˜ í™˜ê²½ ìƒì„±: ì»¨í…Œì´ë„ˆ{container_size}, ë°•ìŠ¤{num_boxes}ê°œ")
        return env
        
    except Exception as e:
        print(f"âŒ í™˜ê²½ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def train_production_model(env, timesteps=50000):
    """í”„ë¡œë•ì…˜ ìµœì  ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ"""
    try:
        import torch
        import torch.nn as nn
        from sb3_contrib import MaskablePPO
        
        print(f"ğŸš€ í”„ë¡œë•ì…˜ í•™ìŠµ ì‹œì‘: {timesteps:,} ìŠ¤í…")
        print(f"ğŸ“Š ìµœì  ì„¤ì •: LR={PRODUCTION_OPTIMAL['learning_rate']:.2e}, "
              f"Steps={PRODUCTION_OPTIMAL['n_steps']}, "
              f"Batch={PRODUCTION_OPTIMAL['batch_size']}")
        
        start_time = time.time()
        
        # ìµœì  ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ìƒì„±
        model = MaskablePPO(
            "MultiInputPolicy",
            env,
            learning_rate=PRODUCTION_OPTIMAL['learning_rate'],
            n_steps=PRODUCTION_OPTIMAL['n_steps'],
            batch_size=PRODUCTION_OPTIMAL['batch_size'],
            n_epochs=PRODUCTION_OPTIMAL['n_epochs'],
            gamma=0.99,
            gae_lambda=PRODUCTION_OPTIMAL['gae_lambda'],
            clip_range=PRODUCTION_OPTIMAL['clip_range'],
            ent_coef=PRODUCTION_OPTIMAL['ent_coef'],
            vf_coef=PRODUCTION_OPTIMAL['vf_coef'],
            max_grad_norm=0.5,
            verbose=1,
            seed=42,
            policy_kwargs=dict(
                net_arch=PRODUCTION_OPTIMAL['net_arch'],
                activation_fn=nn.ReLU,
                share_features_extractor=True,
            )
        )
        
        # í•™ìŠµ ì‹¤í–‰
        model.learn(total_timesteps=timesteps, progress_bar=True)
        
        duration = time.time() - start_time
        print(f"â±ï¸ í•™ìŠµ ì™„ë£Œ: {duration/60:.1f}ë¶„")
        
        return model, duration
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
        return None, 0

def evaluate_production_model(model, container_size=[10, 10, 10], num_boxes=12, n_episodes=50):
    """ê°•í™”ëœ í”„ë¡œë•ì…˜ í‰ê°€ (ë” ë§ì€ ì—í”¼ì†Œë“œ)"""
    print(f"ğŸ” í”„ë¡œë•ì…˜ í‰ê°€ ì‹œì‘: {n_episodes} ì—í”¼ì†Œë“œ")
    
    all_rewards = []
    all_utilizations = []
    placement_counts = []
    success_count = 0
    
    for ep in range(n_episodes):
        seed = 200 + ep * 3  # ë‹¤ì–‘í•œ ì‹œë“œ
        eval_env = create_production_env(container_size, num_boxes, seed)
        
        if eval_env is None:
            continue
        
        obs, _ = eval_env.reset(seed=seed)
        episode_reward = 0.0
        
        for step in range(50):  # ìµœëŒ€ 50ìŠ¤í…
            try:
                action, _ = model.predict(obs, deterministic=False)
                obs, reward, terminated, truncated, info = eval_env.step(action)
                episode_reward += reward
                
                if terminated or truncated:
                    break
                    
            except Exception as e:
                break
        
        # ì„±ê³¼ ê³„ì‚°
        utilization = 0.0
        placed_boxes = 0
        try:
            if hasattr(eval_env.unwrapped, 'container'):
                placed_volume = sum(box.volume for box in eval_env.unwrapped.container.boxes 
                                  if box.position is not None)
                container_volume = eval_env.unwrapped.container.volume
                utilization = placed_volume / container_volume if container_volume > 0 else 0.0
                placed_boxes = sum(1 for box in eval_env.unwrapped.container.boxes 
                                 if box.position is not None)
        except:
            pass
        
        # ì„±ê³µ ê¸°ì¤€: í™œìš©ë¥  25% ì´ìƒ ë˜ëŠ” ë°•ìŠ¤ 50% ì´ìƒ
        if utilization >= 0.25 or placed_boxes >= num_boxes * 0.5:
            success_count += 1
        
        all_rewards.append(episode_reward)
        all_utilizations.append(utilization)
        placement_counts.append(placed_boxes)
        
        if ep < 10 or ep % 10 == 0:
            print(f"   ì—í”¼ì†Œë“œ {ep+1}: ë³´ìƒ={episode_reward:.3f}, "
                  f"í™œìš©ë¥ ={utilization:.1%}, ë°•ìŠ¤={placed_boxes}ê°œ")
        
        eval_env.close()
    
    if not all_rewards:
        return None
    
    results = {
        'mean_reward': np.mean(all_rewards),
        'std_reward': np.std(all_rewards),
        'mean_utilization': np.mean(all_utilizations),
        'std_utilization': np.std(all_utilizations),
        'mean_placement': np.mean(placement_counts),
        'max_placement': max(placement_counts),
        'success_rate': success_count / len(all_rewards),
        'combined_score': np.mean(all_rewards) * 0.3 + np.mean(all_utilizations) * 100 * 0.7,
        'episodes': len(all_rewards),
        'all_rewards': all_rewards,
        'all_utilizations': all_utilizations
    }
    
    return results

def production_final_test(timesteps=50000, eval_episodes=50):
    """í”„ë¡œë•ì…˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ† í”„ë¡œë•ì…˜ ìµœì  ì„¤ì • ìµœì¢… ê²€ì¦ ì‹œì‘")
    print(f"ğŸ“Š ëª©í‘œ: 20.591ì  ì¬í˜„ ë° ì•ˆì •ì„± ê²€ì¦")
    print("="*60)
    
    # í™˜ê²½ ìƒì„±
    container_size = [10, 10, 10]
    num_boxes = 12
    
    env = create_production_env(container_size, num_boxes, 42)
    if env is None:
        return False
    
    # ëª¨ë¸ í•™ìŠµ
    print(f"\nğŸ“ 1ë‹¨ê³„: í”„ë¡œë•ì…˜ ëª¨ë¸ í•™ìŠµ ({timesteps:,} ìŠ¤í…)")
    model, train_time = train_production_model(env, timesteps)
    
    if model is None:
        env.close()
        return False
    
    # ëª¨ë¸ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = f"models/production_optimal_{timestamp}"
    os.makedirs('models', exist_ok=True)
    model.save(model_path)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ê°•í™”ëœ í‰ê°€
    print(f"\nğŸ“Š 2ë‹¨ê³„: ê°•í™”ëœ í‰ê°€ ({eval_episodes} ì—í”¼ì†Œë“œ)")
    results = evaluate_production_model(model, container_size, num_boxes, eval_episodes)
    
    env.close()
    
    if results is None:
        return False
    
    # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ† í”„ë¡œë•ì…˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("="*60)
    print(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {results['combined_score']:.3f}")
    print(f"ğŸ¯ ëª©í‘œ ëŒ€ë¹„: {(results['combined_score']/20.591*100):.1f}% (ëª©í‘œ: 20.591)")
    print(f"ğŸ’° í‰ê·  ë³´ìƒ: {results['mean_reward']:.3f} Â± {results['std_reward']:.3f}")
    print(f"ğŸ“¦ í‰ê·  í™œìš©ë¥ : {results['mean_utilization']:.1%} Â± {results['std_utilization']:.1%}")
    print(f"ğŸ² í‰ê·  ë°°ì¹˜: {results['mean_placement']:.1f}ê°œ (ìµœëŒ€: {results['max_placement']}ê°œ)")
    print(f"âœ… ì„±ê³µë¥ : {results['success_rate']:.1%}")
    print(f"â±ï¸ í•™ìŠµ ì‹œê°„: {train_time/60:.1f}ë¶„")
    
    # ì„±ëŠ¥ íŒì •
    if results['combined_score'] >= 20.0:
        print(f"ğŸ‰ ìš°ìˆ˜! ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„± ë˜ëŠ” ê·¼ì ‘")
    elif results['combined_score'] >= 18.57:
        print(f"âœ… ì„±ê³µ! Phase 3 ëª©í‘œ ë‹¬ì„±")
    else:
        print(f"ğŸ“ˆ ê°œì„  í•„ìš”: ì¶”ê°€ íŠœë‹ ê¶Œì¥")
    
    # ìƒì„¸ ê²°ê³¼ ì €ì¥
    final_results = {
        'timestamp': timestamp,
        'test_type': 'production_final',
        'params': PRODUCTION_OPTIMAL,
        'config': {
            'container_size': container_size,
            'num_boxes': num_boxes,
            'timesteps': timesteps,
            'eval_episodes': eval_episodes
        },
        'performance': results,
        'training_time_minutes': train_time/60,
        'model_path': model_path,
        'target_score': 20.591,
        'achievement_rate': results['combined_score']/20.591*100
    }
    
    results_file = f"results/production_final_{timestamp}.json"
    with open(results_file, 'w') as f:
        json.dump(final_results, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_file}")
    
    return results['combined_score'] >= 18.57

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='í”„ë¡œë•ì…˜ ìµœì  ì„¤ì • ìµœì¢… í…ŒìŠ¤íŠ¸')
    parser.add_argument('--timesteps', type=int, default=50000, help='í•™ìŠµ ìŠ¤í… ìˆ˜')
    parser.add_argument('--episodes', type=int, default=50, help='í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜')
    parser.add_argument('--quick', action='store_true', help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (25000 ìŠ¤í…)')
    
    args = parser.parse_args()
    
    if args.quick:
        timesteps = 25000
        episodes = 30
        print("âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    else:
        timesteps = args.timesteps
        episodes = args.episodes
        print("ğŸ† ì™„ì „ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    print(f"ğŸš€ ì„¤ì •: {timesteps:,} ìŠ¤í…, {episodes} ì—í”¼ì†Œë“œ")
    
    start_time = time.time()
    success = production_final_test(timesteps, episodes)
    total_time = time.time() - start_time
    
    print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    if success:
        print("ğŸ‰ í”„ë¡œë•ì…˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("ğŸ“ˆ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 