#!/usr/bin/env python3
"""
ì ì§„ì  í™•ì¥ í…ŒìŠ¤íŠ¸ - Import ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „
"""

import os
import sys

os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'
sys.path.append('src')

print("ğŸ“ˆ ì ì§„ì  í™•ì¥ í…ŒìŠ¤íŠ¸ (ìˆ˜ì • ë²„ì „)")

OPTIMAL_PARAMS = {
    'learning_rate': 2.6777169756959113e-06,
    'n_steps': 64,      # ì¡°ê¸ˆ ë” í¬ê²Œ
    'batch_size': 8,    # ì¡°ê¸ˆ ë” í¬ê²Œ
    'n_epochs': 2,      # 2 ì—í¬í¬
    'clip_range': 0.17716239549317803,
    'ent_coef': 0.06742268917730829,
    'vf_coef': 0.4545305173856873,
    'gae_lambda': 0.9449228658070746
}

def gradual_test():
    try:
        print("\n1ï¸âƒ£ PyTorch ì„¤ì •...")
        import torch
        
        # PyTorch 2.1+ í˜¸í™˜ ì„¤ì •
        torch.set_default_dtype(torch.float32)  # deprecated ê²½ê³  ìˆ˜ì •
        torch.set_num_threads(2)
        print(f"   âœ… PyTorch {torch.__version__} ì„¤ì • ì™„ë£Œ")
        
        print("\n2ï¸âƒ£ í™˜ê²½ ë“±ë¡...")
        import gymnasium as gym
        from gymnasium.envs.registration import register
        from packing_env import PackingEnv  # ì˜¬ë°”ë¥¸ import
        
        if 'PackingEnv-v0' not in gym.envs.registry:
            register(id='PackingEnv-v0', entry_point='packing_env:PackingEnv')
            print("   âœ… í™˜ê²½ ë“±ë¡ ì™„ë£Œ")
        else:
            print("   âœ… í™˜ê²½ ì´ë¯¸ ë“±ë¡ë¨")
        
        print("\n3ï¸âƒ£ í™•ì¥ëœ í™˜ê²½ ìƒì„±...")
        # ì˜¬ë°”ë¥¸ import
        from utils import boxes_generator
        
        # ì¡°ê¸ˆ ë” í° ë¬¸ì œ
        box_sizes = boxes_generator([6, 6, 6], 4, 42)  # 6x6x6, 4ê°œ ë°•ìŠ¤
        env = gym.make(
            "PackingEnv-v0",
            container_size=[6, 6, 6],
            box_sizes=box_sizes,
            num_visible_boxes=2,
            render_mode=None,
            random_boxes=False,
            only_terminal_reward=False,
        )
        print(f"   âœ… í™•ì¥ëœ í™˜ê²½ ìƒì„± ì„±ê³µ")
        print(f"   ì»¨í…Œì´ë„ˆ: [6, 6, 6], ë°•ìŠ¤: {len(box_sizes)}ê°œ")
        
        print("\n4ï¸âƒ£ í™•ì¥ëœ ëª¨ë¸ ìƒì„±...")
        from sb3_contrib import MaskablePPO
        import torch.nn as nn
        
        model = MaskablePPO(
            "MultiInputPolicy",
            env,
            learning_rate=OPTIMAL_PARAMS['learning_rate'],
            n_steps=OPTIMAL_PARAMS['n_steps'],
            batch_size=OPTIMAL_PARAMS['batch_size'],
            n_epochs=OPTIMAL_PARAMS['n_epochs'],
            gamma=0.99,
            gae_lambda=OPTIMAL_PARAMS['gae_lambda'],
            clip_range=OPTIMAL_PARAMS['clip_range'],
            ent_coef=OPTIMAL_PARAMS['ent_coef'],
            vf_coef=OPTIMAL_PARAMS['vf_coef'],
            max_grad_norm=0.5,
            verbose=0,
            device='cpu',
            policy_kwargs=dict(
                net_arch=[32, 32],  # ì¡°ê¸ˆ ë” í° ë„¤íŠ¸ì›Œí¬
                activation_fn=nn.ReLU,
            )
        )
        print("   âœ… í™•ì¥ëœ ëª¨ë¸ ìƒì„± ì„±ê³µ")
        
        print("\n5ï¸âƒ£ í™•ì¥ëœ í•™ìŠµ ì‹œì‘ (200 ìŠ¤í…)...")
        import time
        start_time = time.time()
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        class ProgressTracker:
            def __init__(self):
                self.step_count = 0
            
            def __call__(self, locals_, globals_):
                self.step_count += 1
                if self.step_count % 50 == 0:
                    progress = (self.step_count / 200) * 100
                    print(f"     ì§„í–‰: {progress:.0f}% ({self.step_count}/200)")
                return True
        
        model.learn(
            total_timesteps=200, 
            progress_bar=False,
            callback=ProgressTracker()
        )
        
        training_time = time.time() - start_time
        print(f"   âœ… í™•ì¥ëœ í•™ìŠµ ì™„ë£Œ: {training_time:.1f}ì´ˆ")
        
        print("\n6ï¸âƒ£ í™•ì¥ëœ í‰ê°€ í…ŒìŠ¤íŠ¸...")
        rewards = []
        utilizations = []
        
        for i in range(3):
            obs, _ = env.reset()
            total_reward = 0
            steps = 0
            
            for step in range(10):  # 10ìŠ¤í…ì”©
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                total_reward += reward
                steps += 1
                if terminated or truncated:
                    break
            
            rewards.append(total_reward)
            
            # í™œìš©ë¥  ê³„ì‚°
            try:
                if hasattr(env.unwrapped, 'container'):
                    placed_volume = sum(box.volume for box in env.unwrapped.container.boxes 
                                      if box.position is not None)
                    container_volume = env.unwrapped.container.volume
                    utilization = placed_volume / container_volume if container_volume > 0 else 0.0
                    utilizations.append(utilization)
                else:
                    utilizations.append(0.0)
            except:
                utilizations.append(0.0)
            
            print(f"   ì—í”¼ì†Œë“œ {i+1}: ë³´ìƒ={total_reward:.3f}, í™œìš©ë¥ ={utilizations[-1]:.1%}")
        
        avg_reward = sum(rewards) / len(rewards)
        avg_utilization = sum(utilizations) / len(utilizations)
        combined_score = avg_reward * 0.3 + avg_utilization * 100 * 0.7
        
        print(f"\nğŸ‰ í™•ì¥ëœ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"   í‰ê·  ë³´ìƒ: {avg_reward:.4f}")
        print(f"   í‰ê·  í™œìš©ë¥ : {avg_utilization:.1%}")
        print(f"   ì¢…í•© ì ìˆ˜: {combined_score:.4f}")
        print(f"   í•™ìŠµ ì‹œê°„: {training_time:.1f}ì´ˆ")
        print(f"   ìµœì  íŒŒë¼ë¯¸í„°ê°€ í™•ì¥ëœ ë¬¸ì œì—ì„œë„ ì˜ ë™ì‘í•©ë‹ˆë‹¤!")
        
        # ì •ë¦¬
        env.close()
        del model
        import gc
        gc.collect()
        
        return True
        
    except Exception as e:
        print(f"âŒ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ í˜„ì¬ í™˜ê²½:")
    print(f"   Python: {sys.version}")
    print(f"   ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
    print(f"   CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}")
    
    success = gradual_test()
    if success:
        print("\nâœ… ì ì§„ì  í™•ì¥ í…ŒìŠ¤íŠ¸ ì™„ì „ ì„±ê³µ!")
        print("ğŸ’¡ ìµœì  íŒŒë¼ë¯¸í„°ê°€ ë” í° ë¬¸ì œì—ì„œë„ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸš€ ì´ì œ ë³¸ê²©ì ì¸ ì‹¤í—˜ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print("ğŸ”§ ì¶”ê°€ ë””ë²„ê¹…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
